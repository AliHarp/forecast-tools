{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import forecast_tools as ft\n",
    "from forecast_tools.baseline import Naive1, SNaive, baseline_estimators\n",
    "from forecast_tools.datasets import load_emergency_dept\n",
    "\n",
    "from forecast_tools.metrics import mean_absolute_error\n",
    "\n",
    "from forecast_tools.model_selection import (cross_validation_score, \n",
    "                                            cross_validation_folds,\n",
    "                                            rolling_forecast_origin, \n",
    "                                            sliding_window)\n",
    "\n",
    "from forecast_tools.metrics import (_forecast_error_functions, \n",
    "                                    mean_absolute_scaled_error)\n",
    "                                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = load_emergency_dept()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mase_cross_validation_score(model, cv, metric, seasonal_period=None):\n",
    "    '''\n",
    "    Mean absolute scaled error cross validation score\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    model: object\n",
    "        forecast model\n",
    "\n",
    "    cv: generator\n",
    "        time series cross validation fold generator\n",
    "        \n",
    "    metric: func(y_true, y_py_red)\n",
    "        forecast error metric\n",
    "\n",
    "    seasonal_period: None or int, optional (default=None)\n",
    "        if none the in-sample one step Naive1 used for scaling.  \n",
    "        if int SNaive is used instead.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    np.array of mase scores\n",
    "    '''\n",
    "    \n",
    "    folds = cross_validation_folds(model, cv)\n",
    "    \n",
    "    scores = []\n",
    "    for y_train, y_true, y_pred in folds:\n",
    "        score = metric(y_true, y_pred, y_train, \n",
    "                       period=seasonal_period)\n",
    "        scores.append(score)\n",
    "        \n",
    "    return np.array(scores)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_naive(y_train, horizon=1, seasonal_period=1, min_train_size='auto', \n",
    "               method='cv', step=1, window_size='auto', metric='mae'):\n",
    "    '''Automatic selection of the 'best' naive benchmark on a 'single' series\n",
    "    \n",
    "    The selection process uses out-of-sample cv performance.\n",
    "    \n",
    "    By default auto_naive uses cross validation to estimate the mean\n",
    "    point forecast peformance of all naive methods.  It selects the method\n",
    "    with the lowest point forecast metric on average.\n",
    "    \n",
    "    If there is limited data for training a basic holdout sample could be\n",
    "    used.\n",
    "    \n",
    "    Dev note: the plan is to update this to work with multiple series.  \n",
    "    It would be best to use MASE for multiple series comparison.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    y_train: array-like\n",
    "        training data.  typically in a pandas.Series, pandas.DataFrame\n",
    "        or numpy.ndarray format. \n",
    "        \n",
    "    horizon: int, optional (default=1)\n",
    "        Forecast horizon. \n",
    "        \n",
    "    seasonal_period: int, optional (default=1)\n",
    "        Frequency of the data.  E.g. 7 for weekly pattern, 12 for monthly\n",
    "        365 for daily.\n",
    "        \n",
    "    min_train_size: int or str, optional (default='auto')\n",
    "        The size of the initial training set (if method=='ro' or 'sw'). \n",
    "        If 'auto' then then min_train_size is set to len(y_train) // 3\n",
    "        If main_train_size='auto' and method='holdout' then \n",
    "        min_train_size = len(y_train) - horizon.\n",
    "        \n",
    "    method: str, optional (default='cv')\n",
    "        out of sample selection method. \n",
    "        'ro' - rolling forecast origin\n",
    "        'sw' - sliding window\n",
    "        'cv' - scores from both ro and sw\n",
    "        'holdout' - single train/test split\n",
    "         Methods'ro' and 'sw' are similar, however, sw has a fixed\n",
    "         window_size and drops older data from training.\n",
    "        \n",
    "    step: int, optional (default=1)\n",
    "        The stride/step of the cross-validation. I.e. the number\n",
    "        of observations to move forward between folds.\n",
    "        \n",
    "    window_size: str or int, optional (default='auto')\n",
    "        The window_size if using sliding window cross validation\n",
    "        When 'auto' and method='sw' then \n",
    "        window_size=len(y_train) // 3\n",
    "        \n",
    "    metric: str, optional (default='mae')\n",
    "        The metric to measure out of sample accuracy.\n",
    "        Options: mase, mae, mape, smape, mse, rmse, me.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        'model': baseline.Forecast\n",
    "        f'{metric}': float\n",
    "        \n",
    "        Contains the model and its CV performance.\n",
    "        \n",
    "    Raises:\n",
    "    -------\n",
    "    ValueError\n",
    "        For invalid method, metric, window_size parameters\n",
    "        \n",
    "    See Also:\n",
    "    --------\n",
    "    forecast_tools.baseline.Naive1\n",
    "    forecast_tools.baseline.SNaive\n",
    "    forecast_tools.baseline.Drift\n",
    "    forecast_tools.baseline.Average\n",
    "    forecast_tools.baseline.EnsembleNaive\n",
    "    forecast_tools.baseline.baseline_estimators\n",
    "    forecast_tools.model_selection.rolling_forecast_origin\n",
    "    forecast_tools.model_selection.sliding_window\n",
    "    forecast_tools.model_selection.mase_cross_validation_score\n",
    "    forecast_tools.metrics.mean_absolute_scaled_error\n",
    "    \n",
    "    Examples:\n",
    "    ---------\n",
    "    Measuring MAE and taking the best method using both\n",
    "    rolling origin and sliding window cross validation\n",
    "    of a 56 day forecast.\n",
    "    \n",
    "    >>> from forecast_tools.datasets import load_emergency_dept\n",
    "    >>> y_train = load_emergency_dept\n",
    "    >>> best = auto_naive(y_train, seasonal_period=7, horizon=56)\n",
    "    >>> best\n",
    "    {'model': Average(), 'mae': 19.63791579700355}\n",
    "    \n",
    "    \n",
    "    Take a step of 7 days between cv folds.\n",
    "    \n",
    "    >>> from forecast_tools.datasets import load_emergency_dept\n",
    "    >>> y_train = load_emergency_dept\n",
    "    >>> best = auto_naive(y_train, seasonal_period=7, horizon=56,\n",
    "        ...               step=7)\n",
    "    >>> best\n",
    "    {'model': Average(), 'mae': 19.675635558539383}\n",
    "    \n",
    "    '''\n",
    "    valid_methods = ['holdout', 'ro', 'sw', 'cv']\n",
    "    metrics = _forecast_error_functions()\n",
    "    metrics['mase'] = mean_absolute_scaled_error\n",
    "    \n",
    "    if method not in valid_methods:\n",
    "        raise ValueError(f\"Method must be in {valid_methods}\")\n",
    "        \n",
    "    if metric not in metrics:\n",
    "        raise ValueError(f\"Please select a metric from {list(metrics.keys())}\")\n",
    "                    \n",
    "    if min_train_size == 'auto':\n",
    "        min_train_size = len(y_train) // 3\n",
    "    elif not type(min_train_size) is int:\n",
    "        raise ValueError(f\"valid min_train_size values are 'auto' or int > 0\")\n",
    "    elif min_train_size < 1:\n",
    "        raise ValueError(f\"valid min_train_size values are 'auto' or int > 0\")\n",
    "        \n",
    "    if window_size == 'auto':\n",
    "        window_size = len(y_train) // 3\n",
    "    elif not type(window_size) is int:\n",
    "        raise ValueError(f\"valid window_size values are 'auto' or int > 0\")\n",
    "    elif window_size < 1:\n",
    "        raise ValueError(f\"valid window_size values are 'auto' or int > 0\")\n",
    "        \n",
    "    baselines = baseline_estimators(seasonal_period)\n",
    "        \n",
    "    method_score = []\n",
    "    if method == 'cv':\n",
    "        for _, model in baselines.items():\n",
    "            cv_ro = rolling_forecast_origin(train=y_train, \n",
    "                                         min_train_size=min_train_size,\n",
    "                                         horizon=horizon, \n",
    "                                         step=step)\n",
    "            \n",
    "            cv_sw = sliding_window(train=y_train, \n",
    "                                   window_size=window_size,\n",
    "                                   horizon=horizon, \n",
    "                                   step=step)\n",
    "            \n",
    "            if metric == 'mase':\n",
    "                score_ro = scaled_cross_validation_score(model, cv_ro, seasonal_period)\n",
    "                score_sw = scaled_cross_validation_score(model, cv_sw, seasonal_period)\n",
    "                          \n",
    "            else:\n",
    "                score_ro = cross_validation_score(model, cv_ro, metrics[metric])\n",
    "                score_sw = cross_validation_score(model, cv_sw, metrics[metric])\n",
    "            \n",
    "            score = np.concatenate([score_ro, score_sw])    \n",
    "            method_score.append(score.mean())\n",
    "            \n",
    "    elif method == 'ro':\n",
    "        for _, model in baselines.items():\n",
    "            cv = rolling_forecast_origin(train=y_train, \n",
    "                                         min_train_size=min_train_size,\n",
    "                                         horizon=horizon, \n",
    "                                         step=step)\n",
    "\n",
    "            if metric == 'mase':\n",
    "                score_ro = scaled_cross_validation_score(model, cv, seasonal_period)\n",
    "                          \n",
    "            else:\n",
    "                score_ro = cross_validation_score(model, cv, metrics[metric])\n",
    "                \n",
    "            method_score.append(score_ro.mean())\n",
    "         \n",
    "    elif method == 'sw':\n",
    "        for _, model in baselines.items():\n",
    "            cv = sliding_window(train=y_train, \n",
    "                                window_size=window_size,\n",
    "                                horizon=horizon, \n",
    "                                step=step)\n",
    "\n",
    "            if metric == 'mase':\n",
    "                score_sw = scaled_cross_validation_score(model, cv, seasonal_period)\n",
    "                          \n",
    "            else:\n",
    "                score_sw = cross_validation_score(model, cv, metrics[metric])\n",
    "                \n",
    "            method_score.append(score_sw.mean())\n",
    "        \n",
    "    else:\n",
    "        #single train test split\n",
    "        min_train_size = len(y_train) - horizon\n",
    "        train = y_train[:min_train_size]\n",
    "        test = y_train[min_train_size:]\n",
    "        \n",
    "        for _, model in baselines.items():\n",
    "            model.fit(train)\n",
    "            y_preds = model.predict(horizon)\n",
    "            if metric == 'mase':\n",
    "                score = metrics[metric](test, y_preds, y_train, seasonal_period)\n",
    "            else:\n",
    "                score = metrics[metric](test, y_preds)\n",
    "                \n",
    "            method_score.append(score.mean())\n",
    "            \n",
    "    method_score = np.array(method_score)\n",
    "    best_index = np.argmin(method_score)\n",
    "    \n",
    "    best = {'model':list(baselines.items())[best_index][1],\n",
    "            f'{metric}':method_score[best_index]}\n",
    "    \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': Average(), 'mase': 0.7081640191784493}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = auto_naive(y_train, seasonal_period=7, horizon=7, method='cv', metric='mase')\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': Average(), 'mase': 0.7086963436693071}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = auto_naive(y_train, horizon=7, metric='mase')\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': Average(), 'mae': 19.675635558539383}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = auto_naive(y_train, seasonal_period=7, horizon=56, step=7)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = auto_naive(ed, seasonal_period=7, horizon=56, method='holdout', metric='mase')\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_cross_validation_score(model, cv, seasonal_period=None):\n",
    "    '''\n",
    "    Mean absolute scaled error cross validation score\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    model: object\n",
    "        forecast model\n",
    "\n",
    "    cv: generator\n",
    "        time series cross validation fold generator\n",
    "        \n",
    "    metric: func(y_true, y_py_red)\n",
    "        forecast error metric\n",
    "\n",
    "    seasonal_period: None or int, optional (default=None)\n",
    "        if none the in-sample one step Naive1 used for scaling.  \n",
    "        if int SNaive is used instead.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    np.array of mase scores\n",
    "    '''\n",
    "    \n",
    "    folds = cross_validation_folds(model, cv)\n",
    "    \n",
    "    scores = []\n",
    "    for y_train, y_true, y_pred in folds:\n",
    "        score = mean_absolute_scaled_error(y_true, y_pred, y_train, \n",
    "                                           period=seasonal_period)\n",
    "        scores.append(score)\n",
    "        \n",
    "    return np.array(scores)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(model, train, test, horizon):\n",
    "    '''\n",
    "    h-step prediction of a model\n",
    "\n",
    "    Returns a tuple of (y_preds, y_train, y_true) of model fit\n",
    "    to training data\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    model - object\n",
    "        forecasting model with .fit(train) and\n",
    "        .predict(horizon) methods\n",
    "\n",
    "    train - array-like\n",
    "        training data\n",
    "\n",
    "    test: array-like\n",
    "        holdout data for testing\n",
    "\n",
    "    horizon: int\n",
    "        forecast horizon\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple (y_pred, y_train, y_true)\n",
    "    '''\n",
    "    y_pred = model.fit_predict(train, horizon)\n",
    "    return train, test, y_pred\n",
    "\n",
    "\n",
    "def cross_validation_folds(model, cv, n_jobs=-1):\n",
    "    '''\n",
    "    Cross validation forecasts\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    model: object\n",
    "        forecast model\n",
    "\n",
    "    cv: object\n",
    "        cross validation generator\n",
    "        i.e. rolling_forecast_origin or sliding_window\n",
    "\n",
    "    n_jobs: int, optional (default=-1)\n",
    "        when -1 runs across all cores\n",
    "        set = 1 to run each cross validation seperately.\n",
    "        using -1 speeds up cross validation of slow running models.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    np.ndarray of tuples\n",
    "    each tuple is (cv_train, cv_test, cv_y_pred)\n",
    "    '''\n",
    "    \n",
    "    cv_folds = [forecast(model, cv_train, cv_test, len(cv_test)) for cv_train, cv_test in cv]\n",
    "    print(cv_folds[0])\n",
    "    return np.array(cv_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_folds(model, cv, n_jobs=-1):\n",
    "    '''\n",
    "    Cross validation forecasts\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    model: object\n",
    "        forecast model\n",
    "\n",
    "    cv: object\n",
    "        cross validation generator\n",
    "        i.e. rolling_forecast_origin or sliding_window\n",
    "\n",
    "    n_jobs: int, optional (default=-1)\n",
    "        when -1 runs across all cores\n",
    "        set = 1 to run each cross validation seperately.\n",
    "        using -1 speeds up cross validation of slow running models.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    np.ndarray of tuples\n",
    "    each tuple is (cv_train, cv_test, cv_y_pred)\n",
    "    '''\n",
    "\n",
    "    cv_folds = \\\n",
    "        Parallel(n_jobs=n_jobs)(delayed(forecast)(model,\n",
    "                                                  cv_train,\n",
    "                                                  cv_test,\n",
    "                                                  len(cv_test))\n",
    "                                for cv_train, cv_test in cv)\n",
    "\n",
    "    return np.array(cv_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 10\n",
    "min_train_size=3\n",
    "horizon=1\n",
    "step=2\n",
    "expected=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mase_cv_number_of_folds_pd(train_size, min_train_size, horizon, step,\n",
    "                                    expected):\n",
    "    '''\n",
    "    check that the number of folds returned from rolling origin\n",
    "    is as expected when data source is a pandas.DataFrame\n",
    "    '''\n",
    "    train = pd.Series(np.arange(train_size))\n",
    "    print(train)\n",
    "    cv = rolling_forecast_origin(train, min_train_size=min_train_size,\n",
    "                                    horizon=horizon, step=step)\n",
    "\n",
    "    mase = mean_absolute_scaled_error\n",
    "    scores = scaled_cross_validation_score(Naive1(), cv)\n",
    "\n",
    "    print(expected, len(scores))\n",
    "    print(scores)\n",
    "    assert expected == len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "5    5\n",
      "6    6\n",
      "7    7\n",
      "8    8\n",
      "9    9\n",
      "dtype: int64\n",
      "4 4\n",
      "[1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "test_mase_cv_number_of_folds_pd(train_size, min_train_size, horizon, step,\n",
    "                                expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mase_cv_number_of_folds_pd(train_size, min_train_size, horizon, step,\n",
    "                                expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(window_size) is int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
