{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#we include some parallel CPU examples to speed up your CV!\n",
    "#if you don't have joblib installed then uncomment the line below.\n",
    "#!pip install joblib\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "#suppress ARIMA warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up till now we have used a single validation period to select our best model.  The weakness of that approach is that it gives you a sample size of 1 (that's better than nothing, but generally poor statistics!).  Time series cross validation is an approach to provide more data points when comparing models. In the classicial time series literature time series cross validation is called a **Rolling Forecast Origin**.  There may also be benefit of taking a **sliding window** approach to cross validaiton.  This second approach maintains a fixed sized training set.  I.e. it drops older values from the time series during validation.\n",
    "\n",
    "## Rolling Forecast Origin\n",
    "\n",
    "The following code and output provide a simplified view of how rolling forecast horizons work in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_forecast_origin(train, min_train_size, horizon):\n",
    "    '''\n",
    "    Rolling forecast origin generator.\n",
    "    '''\n",
    "    for i in range(len(train) - min_train_size - horizon + 1):\n",
    "        split_train = train[:min_train_size+i]\n",
    "        split_val = train[min_train_size+i:min_train_size+i+horizon]\n",
    "        yield split_train, split_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full training set: [2502, 2414, 2800, 2143, 2708, 1900, 2333, 2222]\n",
      "hidden test set: [1234, 3456]\n"
     ]
    }
   ],
   "source": [
    "full_series = [2502, 2414, 2800, 2143, 2708, 1900, 2333, 2222, 1234, 3456]\n",
    "\n",
    "test = full_series[-2:]\n",
    "train = full_series[:-2]\n",
    "print('full training set: {0}'.format(train))\n",
    "print('hidden test set: {0}'.format(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object rolling_forecast_origin at 0x7f47c1cf2f48>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_rolling = rolling_forecast_origin(train, min_train_size=4, horizon=2)\n",
    "cv_rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV[1]\n",
      "Train:\t[2502, 2414, 2800, 2143]\n",
      "Val:\t[2708, 1900]\n",
      "-----\n",
      "CV[2]\n",
      "Train:\t[2502, 2414, 2800, 2143, 2708]\n",
      "Val:\t[1900, 2333]\n",
      "-----\n",
      "CV[3]\n",
      "Train:\t[2502, 2414, 2800, 2143, 2708, 1900]\n",
      "Val:\t[2333, 2222]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for cv_train, cv_val in cv_rolling:\n",
    "    print(f'CV[{i+1}]')\n",
    "    print(f'Train:\\t{cv_train}')\n",
    "    print(f'Val:\\t{cv_val}')\n",
    "    print('-----')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding Window Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(train, window_size, horizon, step=1):\n",
    "    '''\n",
    "    sliding window  generator.\n",
    "    \n",
    "    Parameters:\n",
    "    --------\n",
    "    train: array-like\n",
    "        training data for time series method\n",
    "    \n",
    "    window_size: int\n",
    "        lookback - how much data to include.\n",
    "    \n",
    "    horizon: int\n",
    "        forecast horizon\n",
    "        \n",
    "    step: int, optional (default=1)\n",
    "        step=1 means that a single additional data point is added to the time\n",
    "        series.  increase step to run less splits.\n",
    "        \n",
    "    Returns:\n",
    "        array-like, array-like\n",
    "    \n",
    "        split_training, split_validation\n",
    "    '''\n",
    "    for i in range(0, len(train) - window_size - horizon + 1, step):\n",
    "        split_train = train[i:window_size+i]\n",
    "        split_val = train[i+window_size:window_size+i+horizon]\n",
    "        yield split_train, split_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code tests its with `step=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full training set: [2502, 2414, 2800, 2143, 2708, 1900, 2333, 2222]\n",
      "\n",
      "CV[1]\n",
      "Train:\t[2502, 2414, 2800, 2143]\n",
      "Val:\t[2708]\n",
      "-----\n",
      "CV[2]\n",
      "Train:\t[2414, 2800, 2143, 2708]\n",
      "Val:\t[1900]\n",
      "-----\n",
      "CV[3]\n",
      "Train:\t[2800, 2143, 2708, 1900]\n",
      "Val:\t[2333]\n",
      "-----\n",
      "CV[4]\n",
      "Train:\t[2143, 2708, 1900, 2333]\n",
      "Val:\t[2222]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "cv_sliding = sliding_window(train, window_size=4, horizon=1)\n",
    "\n",
    "print('full training set: {0}\\n'.format(train))\n",
    "\n",
    "i = 0\n",
    "for cv_train, cv_val in cv_sliding:\n",
    "    print(f'CV[{i+1}]')\n",
    "    print(f'Train:\\t{cv_train}')\n",
    "    print(f'Val:\\t{cv_val}')\n",
    "    print('-----')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code tests it with `step=2`.  Note that you get less splits.  The code is less computationally expensive at the cost of less data.  That is probably okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full training set: [2502, 2414, 2800, 2143, 2708, 1900, 2333, 2222]\n",
      "\n",
      "CV[1]\n",
      "Train:\t[2502, 2414, 2800, 2143]\n",
      "Val:\t[2708]\n",
      "-----\n",
      "CV[2]\n",
      "Train:\t[2800, 2143, 2708, 1900]\n",
      "Val:\t[2333]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "cv_sliding = sliding_window(train, window_size=4, horizon=1, step=2)\n",
    "\n",
    "print('full training set: {0}\\n'.format(train))\n",
    "\n",
    "i = 0\n",
    "for cv_train, cv_val in cv_sliding:\n",
    "    print(f'CV[{i+1}]')\n",
    "    print(f'Train:\\t{cv_train}')\n",
    "    print(f'Val:\\t{cv_val}')\n",
    "    print('-----')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Cross Validation Example using Naive1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forecast_tools.baseline import SNaive, Naive1\n",
    "from forecast_tools.datasets import load_emergency_dept\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_emergency_dept()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_accuracy(model, train, test, metric):\n",
    "    '''\n",
    "    Returns forecast accuracy of model fit on \n",
    "    training data and compared against a test set \n",
    "    with a given metric.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    model - object\n",
    "        forecasting model with .fit(train) and\n",
    "        .predict(horizon) methods\n",
    "        \n",
    "    train - array-like\n",
    "        training data\n",
    "        \n",
    "    test: array-like\n",
    "        holdout data for testing\n",
    "        \n",
    "    metric: function\n",
    "        error measure sig (y_true, y_preds)\n",
    "    '''\n",
    "    model.fit(train)\n",
    "    preds = model.predict(len(test))\n",
    "    return metric(y_true=test, y_pred=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_score(model, train, cv, metric, n_jobs=-1):\n",
    "    '''\n",
    "    Calculate cross validation scores\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    model: object\n",
    "        forecast model\n",
    "    \n",
    "    train: array-like\n",
    "        training data\n",
    "        \n",
    "    metric: func(y_true, y_pred)\n",
    "        forecast error metric\n",
    "    \n",
    "    n_jobs: int, optional (default=-1)\n",
    "        when -1 runs across all cores\n",
    "        set = 1 to run each cross validation seperately.\n",
    "        using -1 speeds up cross validation of slow running models.    \n",
    "    '''\n",
    "    cv_scores = Parallel(n_jobs=n_jobs)(delayed(forecast_accuracy)(model, \n",
    "                                                cv_train, \n",
    "                                                cv_test, \n",
    "                                                mean_absolute_error) \n",
    "                              for cv_train, cv_test in cv)\n",
    "\n",
    "    return np.array(cv_scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Naive1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit runs the code multiple times to get an estimate of runtime.\n",
    "#comment if out to run the code only once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run on a single core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "cv = sliding_window(train, window_size=14, horizon=7, step=1)\n",
    "results_1 = cross_validation_score(model, train, cv, mean_absolute_error, \n",
    "                                   n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run across multiple cores by setting `n_jobs=-1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit #should see a little bit of speed up, but not loads with basic model.\n",
    "cv = sliding_window(train, window_size=14, horizon=7, step=1)\n",
    "results_2 = cross_validation_score(model, train, cv, mean_absolute_error,\n",
    "                                       n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(324,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(324,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.653439153439148 10.346957901088238\n"
     ]
    }
   ],
   "source": [
    "print(results_1.mean(), results_1.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just to illustrate that the results are the same - the difference is runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.653439153439148 10.346957901088238\n"
     ]
    }
   ],
   "source": [
    "print(results_2.mean(), results_2.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation example using ARIMA - does it speed up when CV run in Parallel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use ARIMA from pmdarima as that has a similar interface to baseline models.\n",
    "from pmdarima import ARIMA, auto_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ato_model = auto_arima(train, suppress_warnings=True, n_jobs=-1, m=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#auto_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create arima model - reasonably complex model\n",
    "#order=(1, 1, 2), seasonal_order=(2, 0, 2, 7)\n",
    "args = {'order':(1, 1, 2), 'seasonal_order':(2, 0, 2, 7)}\n",
    "model = ARIMA(order=args['order'], seasonal_order=args['seasonal_order'],\n",
    "              enforce_stationarity=False, suppress_warnings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.9 s, sys: 300 ms, total: 38.2 s\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = rolling_forecast_origin(train, min_train_size=320, horizon=7)\n",
    "results_1 = cross_validation_score(model, train, cv, mean_absolute_error, \n",
    "                                   n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comment out %%timeit to run the code only once!\n",
    "\n",
    "you should see a big improvement in performance.  mine went \n",
    "from 12.3 seconds to 2.4 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 517 ms, sys: 292 ms, total: 809 ms\n",
      "Wall time: 3.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = rolling_forecast_origin(train, min_train_size=320, horizon=7)\n",
    "results_2 = cross_validation_score(model, train, cv, mean_absolute_error, \n",
    "                                   n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.58663509219668"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.586662939018318"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
